{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "47ffa9fa-d59d-484f-8e75-e583e3b6afa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iván andrés Trujillo Abella \n",
    "#ivantrujillo1229@gmail.com\n",
    "#Consolidate Thesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1f59c2a1-b29f-4f84-9fae-18d6a5ac917b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Own functions\n",
    "def error_in_date(x, format_date= \"%Y-%m-%d\"):\n",
    "    try:\n",
    "        datetime.strptime(x,format_date)\n",
    "        return False\n",
    "    except:\n",
    "        return True\n",
    "\n",
    "def cleantime(x):\n",
    "    if type(x)==str:\n",
    "        return x.replace(\"00:00:00\", \"\").replace(\" \", \"\")\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "def top_cat(k, cat, df):\n",
    "    otro = []\n",
    "    cat_relative_dict =  df[cat].value_counts(normalize=True).to_dict()\n",
    "    for cat in cat_relative_dict:\n",
    "        if cat_relative_dict[cat]<=k:\n",
    "            otro.append(cat)\n",
    "    return otro\n",
    "\n",
    "\n",
    "def bankyear(df_):\n",
    "    df = df_.copy()\n",
    "    years = [2016, 2017, 2018, 2019]\n",
    "    df['bankrupt-year'] = 0\n",
    "    for firm in df.index:\n",
    "        unchanged = True\n",
    "        for year in years:\n",
    "            if df.loc[firm, 'evento'+str(year)]==1 and unchanged==True:\n",
    "                df.loc[firm,'bankrupt-year']= year\n",
    "                unchanged = False\n",
    "    return df['bankrupt-year']\n",
    "\n",
    "\n",
    "\n",
    "def new_firms(current_df, next_df, key):\n",
    "    firm_first =  set(current_df[key].unique()) -  set(next_df[key].unique())\n",
    "    firm_second =  set(next_df[key].unique()) -  set(current_df[key].unique())\n",
    "    return pd.concat([current_df[current_df[key].isin(firm_first)] , next_df[next_df[key].isin(firm_second)]])\n",
    "\n",
    "\n",
    "# A function\n",
    "def varInEvent(time_base, prefix, var_time_event, df_, lag=1):\n",
    "    df = df_.copy()\n",
    "    df['var*'] = np.nan\n",
    "    for firm in df.index:\n",
    "        time_ocurrence = df.loc[firm, var_time_event]\n",
    "        if time_ocurrence - lag >= time_base:\n",
    "            df.loc[firm, 'var*'] = df.loc[firm, prefix + str(time_ocurrence-lag)]\n",
    "    return df['var*']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fc18f333-ec37-4368-baad-20688e9712c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iván\\Desktop\\Thesis\\Thesis-bankrupt\\Datasets\n"
     ]
    }
   ],
   "source": [
    "cd C:\\Users\\iván\\Desktop\\Thesis\\Thesis-bankrupt\\Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9419b37d-aba0-4e38-a4dc-7eb9dfce731d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "910ee87c-73dc-41c0-bb8e-4ecb85b218d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading datasets\n",
    "dfs = {}\n",
    "years = [2016,2017,2018,2019]\n",
    "for year in years:\n",
    "  dfs['df'+str(year)]  = pd.read_excel('Cáratula-Pymes-'+str(year)+'.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9a0477c8-134f-48f9-9d5e-f49412c04481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########\n",
      "(17799, 31) 2016\n",
      "(17723, 31) 2016\n",
      "(17701, 32) 2016\n",
      "(17701, 32) 2016\n",
      "0\n",
      "(17701, 2) 2016\n",
      "##########\n",
      "(14696, 32) 2017\n",
      "(14656, 32) 2017\n",
      "(14639, 33) 2017\n",
      "(14638, 33) 2017\n",
      "0\n",
      "(14638, 2) 2017\n",
      "##########\n",
      "(14275, 34) 2018\n",
      "(14229, 34) 2018\n",
      "(14212, 35) 2018\n",
      "(14210, 35) 2018\n",
      "1\n",
      "(14210, 2) 2018\n",
      "##########\n",
      "(19185, 36) 2019\n",
      "(19140, 36) 2019\n",
      "(19128, 37) 2019\n",
      "(19125, 37) 2019\n",
      "0\n",
      "(19125, 2) 2019\n"
     ]
    }
   ],
   "source": [
    "for year in years:\n",
    "  print('#'*10)\n",
    "  print(dfs['df'+str(year)].shape , year)\n",
    "  dfs['df'+str(year)]  = dfs['df'+str(year)][dfs['df'+str(year)]['Estado actual']!='EN ETAPA PREOPERATIVA']\n",
    "  print(dfs['df'+str(year)].shape , year)\n",
    "  dfs['df'+str(year)]['Fecha'] = pd.to_datetime( dfs['df'+str(year)][ 'Fecha de Corte'], format= \"%Y-%m-%d\")\n",
    "  dfs['df'+str(year)]  = dfs['df'+str(year)][dfs['df'+str(year)]['Fecha'].dt.month==12] # there is duplicates given present the information two or more times..\n",
    "  print(dfs['df'+str(year)].shape , year)\n",
    "  dfs['df'+str(year)] =  dfs['df'+str(year)][-pd.isnull(dfs['df'+str(year)]['NIT'])]\n",
    "  print(dfs['df'+str(year)].shape , year)\n",
    "  dfs['df'+str(year)]['evento'+str(year)]  = np.where(dfs['df'+str(year)]['Estado actual']!='ACTIVA',1 ,0)\n",
    "  dfs['df'+str(year)] = dfs['df'+str(year)][['evento'+str(year), 'NIT']]\n",
    "  print(dfs['df'+str(year)]['NIT'].duplicated().sum())\n",
    "  print(dfs['df'+str(year)].shape , year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f22fc100-4c85-4b66-8f05-e58fed022d09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "evento2019\n",
       "0    18249\n",
       "1      876\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs['df2019']['evento2019'].value_counts() # Here there are 876 firms,  but since declarate the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6f3307aa-f6ed-4b4e-a1e9-f18faad85d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evento2016\n",
      "0    17193\n",
      "1      508\n",
      "Name: count, dtype: int64\n",
      "evento2017\n",
      "0    14019\n",
      "1      619\n",
      "Name: count, dtype: int64\n",
      "evento2018\n",
      "0    13445\n",
      "1      765\n",
      "Name: count, dtype: int64\n",
      "evento2019\n",
      "0    18249\n",
      "1      876\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for year in range(2016,2020):\n",
    "    print(dfs['df'+str(year)]['evento'+str(year)].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6247348b-3b0c-4c6c-960a-a24a3455c36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "full = dfs['df2016'].copy()\n",
    "for year in range(2017,2020):\n",
    "    clients= new_firms(full,dfs['df'+str(year)], 'NIT')\n",
    "    full = full.merge(dfs['df'+str(year)], on='NIT', how='inner', suffixes=(None, 'to_remove'))\n",
    "    duplicated = [x for x in full.columns if 'to_remove' in x]\n",
    "    full.drop(columns=duplicated, inplace=True)\n",
    "    full = pd.concat([full, clients])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "06a8edf1-ccc5-4b7b-9d6f-c23aa1992797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full['NIT'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2fb3b620-8288-4daa-9972-22ca625db9f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "evento2019\n",
       "0.0    18250\n",
       "1.0      876\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full['evento2019'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5f338521-b526-433f-8c92-bc695f7c5e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time-event\n",
       "0       25931\n",
       "2016      508\n",
       "2019      282\n",
       "2018      257\n",
       "2017      232\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full = full[-full['NIT'].duplicated()].reset_index(drop=True)\n",
    "full['time-event'] =bankyear(full)\n",
    "full['time-event'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9b0e1e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time-event\n",
      "0       25931\n",
      "2019      282\n",
      "2018      257\n",
      "2017      232\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## Draw firmst that enter to process in 2016 to avoid bias in indicators...\n",
    "full = full[full['evento2016']!=1]\n",
    "print(full['time-event'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "aa29c0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "full['event'] = (full['time-event']!=0).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0918c852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "event\n",
       "0    25931\n",
       "1      771\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full['event'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cd6787fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "unconverted data remains when parsing with format \"%Y-%m-%d\": \"T00:00:00.0+00:00\", at position 13. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[76], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m EFSS[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mefs\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(year)] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mESF-Pymes-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(year)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m year \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2016\u001b[39m:\n\u001b[1;32m---> 21\u001b[0m     EFSS[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mefs2016\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m EFSS[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mefs2016\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEFSS\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mefs2016\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPeriodo\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mY-\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mm-\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39myear\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m2016\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1046\u001b[0m, in \u001b[0;36mto_datetime\u001b[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[0;32m   1044\u001b[0m             result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mtz_localize(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutc\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1045\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, ABCSeries):\n\u001b[1;32m-> 1046\u001b[0m     cache_array \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_listlike\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1047\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cache_array\u001b[38;5;241m.\u001b[39mempty:\n\u001b[0;32m   1048\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mmap(cache_array)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:250\u001b[0m, in \u001b[0;36m_maybe_cache\u001b[1;34m(arg, format, cache, convert_listlike)\u001b[0m\n\u001b[0;32m    248\u001b[0m unique_dates \u001b[38;5;241m=\u001b[39m unique(arg)\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(unique_dates) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(arg):\n\u001b[1;32m--> 250\u001b[0m     cache_dates \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43munique_dates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;66;03m# GH#45319\u001b[39;00m\n\u001b[0;32m    252\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:453\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[1;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;66;03m# `format` could be inferred, or user didn't ask for mixed-format parsing.\u001b[39;00m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_array_strptime_with_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    455\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m objects_to_datetime64ns(\n\u001b[0;32m    456\u001b[0m     arg,\n\u001b[0;32m    457\u001b[0m     dayfirst\u001b[38;5;241m=\u001b[39mdayfirst,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    461\u001b[0m     allow_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    462\u001b[0m )\n\u001b[0;32m    464\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    465\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[0;32m    466\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:484\u001b[0m, in \u001b[0;36m_array_strptime_with_fallback\u001b[1;34m(arg, name, utc, fmt, exact, errors)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_array_strptime_with_fallback\u001b[39m(\n\u001b[0;32m    474\u001b[0m     arg,\n\u001b[0;32m    475\u001b[0m     name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    479\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m    480\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Index:\n\u001b[0;32m    481\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;124;03m    Call array_strptime, with fallback behavior depending on 'errors'.\u001b[39;00m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 484\u001b[0m     result, timezones \u001b[38;5;241m=\u001b[39m \u001b[43marray_strptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    485\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(tz \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m tz \u001b[38;5;129;01min\u001b[39;00m timezones):\n\u001b[0;32m    486\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _return_parsed_timezone_results(result, timezones, utc, name)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\tslibs\\strptime.pyx:530\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\tslibs\\strptime.pyx:355\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: unconverted data remains when parsing with format \"%Y-%m-%d\": \"T00:00:00.0+00:00\", at position 13. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this."
     ]
    }
   ],
   "source": [
    "ERIS={}\n",
    "EFSS={}\n",
    "for year in range(2016,2019):\n",
    "    # loops in ERI\n",
    "   # ERIS['eri'+str(year)] = pd.read_excel('ERI-Pymes-'+str(year)+'.xlsx')\n",
    "   # ERIS['eri'+str(year)]['Fecha'] = pd.to_datetime( ERIS['eri'+str(year)][ 'Fecha de Corte'], format= \"%Y-%m-%d\")\n",
    "   # ERIS['eri'+str(year)] = ERIS['eri'+str(year)][ERIS['eri'+str(year)]['Fecha'].dt.month==12]\n",
    "   # if year==2016:\n",
    "   #     ERIS['eri2016'] = ERIS['eri2016'][pd.to_datetime( ERIS['eri2016'][ 'Periodo'], format= \"%Y-%m-%d\").dt.year==2016]\n",
    "   #     ERIS['eri2016'] = ERIS['eri2016'][pd.to_datetime( ERIS['eri2016'][ 'Periodo'], format= \"%Y-%m-%d\").dt.month==12]\n",
    "    #    ERIS['eri2016'] = ERIS['eri2016'][pd.to_datetime( ERIS['eri2016'][ 'Periodo'], format= \"%Y-%m-%d\").dt.day==31]\n",
    "   # else:\n",
    "    #    ERIS['eri'+str(year)] = ERIS['eri'+str(year)][ERIS['eri'+str(year)]['Periodo']=='Periodo Actual']\n",
    "    #    ERIS['eri'+str(year)] = ERIS['eri'+str(year)][pd.to_datetime(ERIS['eri'+str(year)]['Fecha de Corte'], format= \"%Y-%m-%d\").dt.day==31]\n",
    "\n",
    "    #ERIS['eri'+str(year)][-ERIS['eri'+str(year)]['NIT'].duplicated()].reset_index(drop=True)\n",
    "\n",
    "    # loops in efs\n",
    "    EFSS['efs'+str(year)] = pd.read_excel('ESF-Pymes-'+str(year)+'.xlsx')\n",
    "    if year == 2016:\n",
    "        EFSS['efs2016'] = EFSS['efs2016'][pd.to_datetime(EFSS['efs2016']['Periodo'], format= \"%Y-%m-%d\").dt.year==2016]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7010f70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "EFSS['efs2016'][EFSS['efs2016']['NIT'].duplicated(keep=False)].to_excel('review.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "72d6c7bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "unconverted data remains when parsing with format \"%Y-%m-%d\": \"T00:00:00.0+00:00\", at position 13. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[84], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEFSS\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mefs2016\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPeriodo\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mY-\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mm-\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1046\u001b[0m, in \u001b[0;36mto_datetime\u001b[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[0;32m   1044\u001b[0m             result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mtz_localize(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutc\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1045\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, ABCSeries):\n\u001b[1;32m-> 1046\u001b[0m     cache_array \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_listlike\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1047\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cache_array\u001b[38;5;241m.\u001b[39mempty:\n\u001b[0;32m   1048\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mmap(cache_array)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:250\u001b[0m, in \u001b[0;36m_maybe_cache\u001b[1;34m(arg, format, cache, convert_listlike)\u001b[0m\n\u001b[0;32m    248\u001b[0m unique_dates \u001b[38;5;241m=\u001b[39m unique(arg)\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(unique_dates) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(arg):\n\u001b[1;32m--> 250\u001b[0m     cache_dates \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43munique_dates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;66;03m# GH#45319\u001b[39;00m\n\u001b[0;32m    252\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:453\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[1;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;66;03m# `format` could be inferred, or user didn't ask for mixed-format parsing.\u001b[39;00m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_array_strptime_with_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    455\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m objects_to_datetime64ns(\n\u001b[0;32m    456\u001b[0m     arg,\n\u001b[0;32m    457\u001b[0m     dayfirst\u001b[38;5;241m=\u001b[39mdayfirst,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    461\u001b[0m     allow_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    462\u001b[0m )\n\u001b[0;32m    464\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    465\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[0;32m    466\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:484\u001b[0m, in \u001b[0;36m_array_strptime_with_fallback\u001b[1;34m(arg, name, utc, fmt, exact, errors)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_array_strptime_with_fallback\u001b[39m(\n\u001b[0;32m    474\u001b[0m     arg,\n\u001b[0;32m    475\u001b[0m     name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    479\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m    480\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Index:\n\u001b[0;32m    481\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;124;03m    Call array_strptime, with fallback behavior depending on 'errors'.\u001b[39;00m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 484\u001b[0m     result, timezones \u001b[38;5;241m=\u001b[39m \u001b[43marray_strptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    485\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(tz \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m tz \u001b[38;5;129;01min\u001b[39;00m timezones):\n\u001b[0;32m    486\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _return_parsed_timezone_results(result, timezones, utc, name)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\tslibs\\strptime.pyx:530\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\tslibs\\strptime.pyx:355\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: unconverted data remains when parsing with format \"%Y-%m-%d\": \"T00:00:00.0+00:00\", at position 13. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this."
     ]
    }
   ],
   "source": [
    "pd.to_datetime(EFSS['efs2016']['Periodo'], format= \"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "84d50ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2016-03-31'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EFSS['efs2016']['Periodo'].loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "aa154749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2016-03-31', '2015-12-31', '2015-01-01', '2016-06-30',\n",
       "       '2016-07-31', '2016-09-30', '2016-10-31', '2016-11-30',\n",
       "       '2016-12-31', '2014-12-31', '2015-12-01', '2016-01-01',\n",
       "       '2015-08-31', '2015-01-01T00:00:00.0+00:00', '2016-12-20',\n",
       "       '2016-08-31', '2015-01-31'], dtype=object)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EFSS['efs2016']['Periodo'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e10e96d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = ['2015-01-01T00:00:00.0+00:00', '2016-12-20']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "94e7331d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2015-01-01T00:00:00.0+00:00', '2016-12-20']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "bb31c65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_date(x):\n",
    "    return x[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "26ec01b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b62b9ec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2015, 1, 1, 0, 0)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.strptime(clean_date('2015-01-01T00:00:00.0+00:00'), '%Y-%m-%d')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
