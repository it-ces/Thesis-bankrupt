{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e5e99c8",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/it-ces/Thesis-bankrupt/blob/main/Notebooks/Models(Thesis).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79e99a90",
   "metadata": {
    "id": "79e99a90"
   },
   "outputs": [],
   "source": [
    "################################\n",
    "#         LIBRARIES            #\n",
    "################################\n",
    "\n",
    "## For processing data\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "## To graph\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#To describe\n",
    "\n",
    "from tableone  import TableOne\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "## To modeling\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# split and grid\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "## Assesment\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support, confusion_matrix, precision_score, recall_score, roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c03d828",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "#   Our Functions   (I)       #\n",
    "################################\n",
    "def percentage_nulls(df):\n",
    "    \"\"\"\n",
    "    This function returns a dictionary with the column and \n",
    "    the porcentage of missing values\n",
    "    \"\"\"\n",
    "    N_rows = df.shape[0]\n",
    "    vars_ = {}\n",
    "    for var in df_consumo.columns:\n",
    "        vars_[var]=(df_consumo[var].isnull().sum() / N_rows)\n",
    "    return vars_\n",
    "\n",
    "\n",
    "def removing_cols(df, percentages_dict, threshold):\n",
    "    \"\"\"\n",
    "    Receive a dictionary with the percatege of missing of each varaible and drop them\n",
    "    according to the threshold defined\n",
    "    \"\"\"\n",
    "    df_ = df.copy()\n",
    "    for var in percentages_dict:\n",
    "        if percentages_dict[var] > threshold:\n",
    "            df_.drop(columns = [var], inplace=True)\n",
    "    return df_\n",
    "\n",
    "\n",
    "def breakdown_vars(df):\n",
    "    \"\"\"\n",
    "    This function allow us categorize accodign to numerical or not\n",
    "    \"\"\"\n",
    "    categorial = []\n",
    "    nonormal = []\n",
    "    normal = []\n",
    "    for t in df.columns:\n",
    "        if df[t].dtypes==\"object\" or df[t].dtypes.name=='category':\n",
    "            categorial.append(t)\n",
    "        if df[t].dtypes==\"int64\" or df[t].dtypes==\"float64\":\n",
    "                n,p = stats.shapiro(df[t])\n",
    "                if p<0.05:\n",
    "                    nonormal.append(t)\n",
    "                else: \n",
    "                    normal.append(t)\n",
    "    return categorial, nonormal, normal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8J9786AKwPqG",
   "metadata": {
    "id": "8J9786AKwPqG"
   },
   "outputs": [],
   "source": [
    "################################\n",
    "#   Our Functions   (II)       #\n",
    "################################\n",
    "def std_z(nums, df_, event):\n",
    "    \"\"\"\n",
    "    standardizing nums(numerical) variables\n",
    "    \"\"\"\n",
    "    df = df_.copy()\n",
    "    for col in nums:\n",
    "        if col != event:\n",
    "            df[col] = (df[col] - df[col].mean())/df[col].std()\n",
    "    return df\n",
    "\n",
    "\n",
    "def Xy(df_,target):\n",
    "    \"\"\"\n",
    "    Split the data in X,y to ML implementations\n",
    "    \"\"\"\n",
    "    df = df_.copy()\n",
    "    X = df.loc[ : , df.columns != target]\n",
    "    y = df[target]\n",
    "    return X,y\n",
    "\n",
    "\n",
    "def dummies_ohe(df_,cats):\n",
    "    \"\"\"\n",
    "    Returns a dataframe with dummies,and dropped the categorical in original\n",
    "    the cats arguments receive the cats to transform.\n",
    "    \"\"\"\n",
    "    df = df_.copy()\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    ohe = OneHotEncoder(drop='first',handle_unknown='ignore', sparse_output=False)\n",
    "    dummies = pd.DataFrame(ohe.fit_transform(df[cats]))\n",
    "    dummies.columns = ohe.get_feature_names_out()  #Names ohe.get_feature_names_out()-> all dummies\n",
    "    df.drop(columns=cats, inplace=True)\n",
    "    df = pd.concat([df,dummies], axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def varInEvent(time_base, time_last, time_target, prefix, var_time_event, df_, lag=1, mean=True):\n",
    "    \"\"\" put time_target  = 0 if you use mean=True\"\"\"\n",
    "    df = df_.copy()\n",
    "    df['var*'] = np.nan\n",
    "    for firm in df.index:\n",
    "        time_ocurrence = df.loc[firm, var_time_event]\n",
    "        if time_ocurrence - lag >= time_base:\n",
    "            df.loc[firm, 'var*'] = df.loc[firm, prefix + str(int(time_ocurrence-lag))]\n",
    "        if mean==True:\n",
    "            to_mean =  [prefix+str(int(time)) for time in range(time_base, time_last+1)]\n",
    "            df['var*'] =np.where(df[var_time_event]==0, df[to_mean].mean(axis=1), df['var*'])\n",
    "        else:\n",
    "            df['var*'] =np.where(df[var_time_event]==0, df[prefix+str(time_target-lag)], df['var*'])\n",
    "    return df['var*']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "nT9OQKOowFK8",
   "metadata": {
    "id": "nT9OQKOowFK8"
   },
   "outputs": [],
   "source": [
    "################################\n",
    "#   Models with Grid search    #\n",
    "################################\n",
    "\n",
    "\n",
    "# Grid search hyperparameters for a LOGISTIC REGRESSION model\n",
    "def grid_lr(X_train, y_train):\n",
    "    model = LogisticRegression(random_state=666, max_iter=1000)\n",
    "    class_weight =  [{0:0.5, 1:0.5}, {0:0.1, 1:0.9}, {0:0.2, 1:0.8}]\n",
    "    solvers = ['liblinear']\n",
    "    penalty = ['l2','l1']\n",
    "    c_values = [ 10, 1.0, 0.1, 0.01, 0.001, ]\n",
    "    grid = dict(solver=solvers,penalty=penalty,C=c_values, class_weight= class_weight)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv,\n",
    "                           scoring='f1',error_score='raise')\n",
    "    grid_result = grid_search.fit(X_train, y_train)\n",
    "    return  grid_result.best_estimator_\n",
    "\n",
    "\n",
    "# Grid search hyperaparmeters for DECISION TREE model\n",
    "def grid_dt(X_train, y_train):\n",
    "    model = DecisionTreeClassifier(random_state=666)\n",
    "    class_weight =  [{0:0.5, 1:0.5}, {0:0.1, 1:0.9}, {0:0.2, 1:0.8}]\n",
    "    max_depth = None,\n",
    "    min_samples_leaf = [5, 10, 20, 50, 100]\n",
    "    criterion  = [\"gini\", \"entropy\"]\n",
    "    grid = dict(class_weight=class_weight, max_depth=max_depth, min_samples_leaf=min_samples_leaf, criterion=criterion)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv,\n",
    "                           scoring='f1',error_score=0)\n",
    "    grid_result = grid_search.fit(X_train, y_train)\n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "\n",
    "\n",
    "# Grid search hyperparameters for MULTILAYER PERCEPTRON model\n",
    "def grid_MLP(X_train, y_train):\n",
    "    model = MLPClassifier(random_state=1, max_iter=300)\n",
    "    hidden_layer_sizes = [(8,), (100,)]\n",
    "    activation =  ['tanh', 'relu', 'logistic']\n",
    "    solver =  ['sgd', 'adam']\n",
    "    alpha  = [0.0001, 0.05]\n",
    "    #'learning_rate': ['constant','adaptive'], }\n",
    "    grid = dict(hidden_layer_sizes=hidden_layer_sizes, activation= activation, solver= solver)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv,\n",
    "                           scoring='f1',error_score='raise')\n",
    "    grid_result = grid_search.fit(X_train, y_train)\n",
    "    return  grid_result.best_estimator_\n",
    "\n",
    "#######################################################\n",
    "#                                                     #\n",
    "#                RATIOS                               #\n",
    "#                                                     #   \n",
    "#######################################################\n",
    "\n",
    "\n",
    "def ratios(df_,):\n",
    "    df = df_.copy()\n",
    "  # Marge de ganancia bruta (MGB)\n",
    "  # Ganancia bruta / ingresos de actividades ordianrias\n",
    "    df['MGB'] = df['Ganancia bruta'] / df['Ingresos de actividades ordinarias']\n",
    "  # Remember that ganancia bruta is:\n",
    "    df['Ingresos de actividades ordinarias'] - df['Costo de ventas']\n",
    "  ## Margen de ganancia Neta (MGN)\n",
    "  #df['Ganancia (p√©rdida) antes de impuestos'] - df['Ingreso (gasto) por impuestos'] #esto es el resultado del periodo\n",
    "    #df[ 'Ganancia (p√©rdida)'] # que en la base resultado del periodo es esta variable\n",
    "    df['MGN'] = df[ 'Ganancia (p√©rdida)'] /  df['Ingresos de actividades ordinarias']\n",
    "  # Rendimiento del patrimonio (ROE)\n",
    "    df['ROE'] = df['Ganancia (p√©rdida)']/ df['Patrimonio total']\n",
    "  # Rendimiento del Activo (ROA)\n",
    "    df['ROA'] = df['Ganancia (p√©rdida)']/ df['Total de activos']\n",
    "  ## NIVEL DE ENDEUDAMIENTO (NE)\n",
    "    df['NE'] = df['Total pasivos'] / df['Total de activos']\n",
    "  ## Concenttraci√≥n de Pasivos a corto plazo (PCP)\n",
    "    df['PCP'] = df['Pasivos corrientes totales'] / df['Total pasivos']\n",
    "  ## Endeudamiento Financiero (EF)\n",
    "  ## Crear primero otros pasivos financieros\n",
    "   # df['Otros pasivos financieros'] = df['Otros pasivos financieros corrientes'] + df['Otros activos no financieros corrientes']\n",
    "    #df['EF'] = df['Otros pasivos financieros'] /  df['Ingresos de actividades ordinarias']\n",
    "  ## Impacto de la carga financiera (IF)\n",
    "    #df['IF'] = df['Costos financieros']/ df['Ingresos de actividades ordinarias']\n",
    "  ## ALTMAN\n",
    "    df['Ax1'] = (df['Activos corrientes totales'] - df['Pasivos corrientes totales'])/df['Total de activos']\n",
    "    df['Ax2'] = (df['Ganancias acumuladas'] / df['Total de activos'])\n",
    "    return df\n",
    "\n",
    "#######################################################\n",
    "#                                                     #\n",
    "#        NULL variables and imputation                #\n",
    "#                                                     #   \n",
    "#######################################################\n",
    "\n",
    "\n",
    "def complete_vars(df):\n",
    "    \"\"\"\n",
    "    percentage of columns with information\n",
    "    \"\"\"\n",
    "    df_ = df.copy()\n",
    "    N_cols = df_.shape[1]\n",
    "    return 1 - df_.apply(lambda x: pd.isnull(x)).sum(axis=1)/N_cols\n",
    "\n",
    "\n",
    "def imputation_mean(df_, target_var, condition_var, condition_value):\n",
    "    \"\"\"\n",
    "    target_var: The variable that we want imputate\n",
    "    condicion_var: The variable that we want uses to stratify the imputation \n",
    "    \"\"\"\n",
    "    df = df_.copy()\n",
    "    indices = df[df[condition_var]==condition_value].index\n",
    "    mean_to_replace = df[df[condition_var]==condition_value][target_var].mean()\n",
    "    df.loc[indices, target_var] = df[df[condition_var]==condition_value][target_var].replace(np.nan, mean_to_replace)\n",
    "    return df[target_var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e514290",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "#                                                     #\n",
    "#                POOLED DATABASE                      #\n",
    "#                                                     #   \n",
    "#######################################################\n",
    "url = \"https://raw.githubusercontent.com/it-ces/Thesis-bankrupt/main/Datasets/database-to-model.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "#df['Patrimonio total'] = varInEvent(2016, 2018, 0, 'Patrimonio total-', 'time-event', df)\n",
    "\n",
    "## To check the construction of variables adecuately\n",
    "#patrimonios = ['Patrimonio total-'+str(year) for year in range(2016,2019)]\n",
    "#df[patrimonios + ['Patrimonio total', 'event' ,'time-event','NIT'] ].to_excel('revisar.xlsx')\n",
    "\n",
    "\n",
    "\n",
    "VARS = ['Ganancia bruta', 'Ganancia (p√©rdida)','Ingresos de actividades ordinarias' , 'Costo de ventas', 'Patrimonio total',\n",
    "     'Total pasivos', 'Total de activos', 'Ganancias acumuladas',  'Pasivos corrientes totales',  'Activos corrientes totales']\n",
    "\n",
    "df.rename(columns={'Clasificaci√≥n Industrial Internacional Uniforme Versi√≥n 4 A.C':'Sector'}, inplace=True)\n",
    "\n",
    "###################################\n",
    "# Activate the following          #\n",
    "# loop to reconstruc the database #\n",
    "#                                 #\n",
    "###################################\n",
    "\n",
    "#for var in VARS:\n",
    "    #df[var] = varInEvent(2016, 2018, 0, var+'-', 'time-event', df)\n",
    "#df.to_csv(\"Datapooled.csv\")\n",
    "\n",
    "#for var in VARS:\n",
    "    #df[var] = varInEvent(2016, 2018, 0, var+'-', 'time-event', df, lag=2)\n",
    "#df.to_csv(\"Datapooled2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74a30265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['NIT'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "69ddafbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event\n",
      "0.0    16488\n",
      "1.0      318\n",
      "Name: count, dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 771 entries, 4 to 26499\n",
      "Data columns (total 14 columns):\n",
      " #   Column                              Non-Null Count  Dtype  \n",
      "---  ------                              --------------  -----  \n",
      " 0   Ganancia bruta                      353 non-null    float64\n",
      " 1   Ganancia (p√©rdida)                  353 non-null    float64\n",
      " 2   Ingresos de actividades ordinarias  353 non-null    float64\n",
      " 3   Costo de ventas                     330 non-null    float64\n",
      " 4   Patrimonio total                    353 non-null    float64\n",
      " 5   Total pasivos                       353 non-null    float64\n",
      " 6   Total de activos                    353 non-null    float64\n",
      " 7   Ganancias acumuladas                351 non-null    float64\n",
      " 8   Pasivos corrientes totales          352 non-null    float64\n",
      " 9   Activos corrientes totales          353 non-null    float64\n",
      " 10  NIT                                 771 non-null    float64\n",
      " 11  event                               771 non-null    float64\n",
      " 12  time-event                          771 non-null    float64\n",
      " 13  Sector                              771 non-null    object \n",
      "dtypes: float64(13), object(1)\n",
      "memory usage: 90.4+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 328 entries, 4 to 14903\n",
      "Data columns (total 15 columns):\n",
      " #   Column                              Non-Null Count  Dtype  \n",
      "---  ------                              --------------  -----  \n",
      " 0   Ganancia bruta                      328 non-null    float64\n",
      " 1   Ganancia (p√©rdida)                  328 non-null    float64\n",
      " 2   Ingresos de actividades ordinarias  328 non-null    float64\n",
      " 3   Costo de ventas                     328 non-null    float64\n",
      " 4   Patrimonio total                    328 non-null    float64\n",
      " 5   Total pasivos                       328 non-null    float64\n",
      " 6   Total de activos                    328 non-null    float64\n",
      " 7   Ganancias acumuladas                328 non-null    float64\n",
      " 8   Pasivos corrientes totales          328 non-null    float64\n",
      " 9   Activos corrientes totales          328 non-null    float64\n",
      " 10  NIT                                 328 non-null    float64\n",
      " 11  event                               328 non-null    float64\n",
      " 12  time-event                          328 non-null    float64\n",
      " 13  Sector                              328 non-null    object \n",
      " 14  complete-vars                       328 non-null    float64\n",
      "dtypes: float64(14), object(1)\n",
      "memory usage: 41.0+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 328 entries, 4 to 14903\n",
      "Data columns (total 23 columns):\n",
      " #   Column                              Non-Null Count  Dtype  \n",
      "---  ------                              --------------  -----  \n",
      " 0   Ganancia bruta                      328 non-null    float64\n",
      " 1   Ganancia (p√©rdida)                  328 non-null    float64\n",
      " 2   Ingresos de actividades ordinarias  328 non-null    float64\n",
      " 3   Costo de ventas                     328 non-null    float64\n",
      " 4   Patrimonio total                    328 non-null    float64\n",
      " 5   Total pasivos                       328 non-null    float64\n",
      " 6   Total de activos                    328 non-null    float64\n",
      " 7   Ganancias acumuladas                328 non-null    float64\n",
      " 8   Pasivos corrientes totales          328 non-null    float64\n",
      " 9   Activos corrientes totales          328 non-null    float64\n",
      " 10  NIT                                 328 non-null    float64\n",
      " 11  event                               328 non-null    float64\n",
      " 12  time-event                          328 non-null    float64\n",
      " 13  Sector                              328 non-null    object \n",
      " 14  complete-vars                       328 non-null    float64\n",
      " 15  MGB                                 320 non-null    float64\n",
      " 16  MGN                                 326 non-null    float64\n",
      " 17  ROE                                 328 non-null    float64\n",
      " 18  ROA                                 328 non-null    float64\n",
      " 19  NE                                  328 non-null    float64\n",
      " 20  PCP                                 327 non-null    float64\n",
      " 21  Ax1                                 328 non-null    float64\n",
      " 22  Ax2                                 328 non-null    float64\n",
      "dtypes: float64(22), object(1)\n",
      "memory usage: 61.5+ KB\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iv√°n\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\stats\\_morestats.py:1882: UserWarning: p-value may not be accurate for N > 5000.\n",
      "  warnings.warn(\"p-value may not be accurate for N > 5000.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">Grouped by event</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Missing</th>\n",
       "      <th>Overall</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>P-Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>n</th>\n",
       "      <th></th>\n",
       "      <td></td>\n",
       "      <td>16806</td>\n",
       "      <td>16488</td>\n",
       "      <td>318</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">time-event, n (%)</th>\n",
       "      <th>0.0</th>\n",
       "      <td>0</td>\n",
       "      <td>16488 (98.11)</td>\n",
       "      <td>16488 (100.00)</td>\n",
       "      <td></td>\n",
       "      <td>&lt;0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017.0</th>\n",
       "      <td></td>\n",
       "      <td>99 (0.59)</td>\n",
       "      <td></td>\n",
       "      <td>99 (31.13)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018.0</th>\n",
       "      <td></td>\n",
       "      <td>96 (0.57)</td>\n",
       "      <td></td>\n",
       "      <td>96 (30.19)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019.0</th>\n",
       "      <td></td>\n",
       "      <td>123 (0.73)</td>\n",
       "      <td></td>\n",
       "      <td>123 (38.68)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MGB, median [Q1,Q3]</th>\n",
       "      <th></th>\n",
       "      <td>0</td>\n",
       "      <td>0.31 [0.18,0.56]</td>\n",
       "      <td>0.32 [0.18,0.56]</td>\n",
       "      <td>0.26 [0.14,0.41]</td>\n",
       "      <td>&lt;0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MGN, median [Q1,Q3]</th>\n",
       "      <th></th>\n",
       "      <td>0</td>\n",
       "      <td>0.03 [0.00,0.08]</td>\n",
       "      <td>0.03 [0.00,0.08]</td>\n",
       "      <td>-0.02 [-0.18,0.03]</td>\n",
       "      <td>&lt;0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROE, median [Q1,Q3]</th>\n",
       "      <th></th>\n",
       "      <td>0</td>\n",
       "      <td>0.07 [0.01,0.16]</td>\n",
       "      <td>0.07 [0.01,0.16]</td>\n",
       "      <td>0.01 [-0.18,0.09]</td>\n",
       "      <td>&lt;0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROA, median [Q1,Q3]</th>\n",
       "      <th></th>\n",
       "      <td>0</td>\n",
       "      <td>0.03 [0.00,0.06]</td>\n",
       "      <td>0.03 [0.00,0.07]</td>\n",
       "      <td>-0.01 [-0.09,0.01]</td>\n",
       "      <td>&lt;0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NE, median [Q1,Q3]</th>\n",
       "      <th></th>\n",
       "      <td>0</td>\n",
       "      <td>0.53 [0.32,0.72]</td>\n",
       "      <td>0.52 [0.32,0.72]</td>\n",
       "      <td>0.74 [0.59,0.88]</td>\n",
       "      <td>&lt;0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCP, median [Q1,Q3]</th>\n",
       "      <th></th>\n",
       "      <td>0</td>\n",
       "      <td>0.75 [0.45,0.98]</td>\n",
       "      <td>0.75 [0.45,0.98]</td>\n",
       "      <td>0.53 [0.28,0.87]</td>\n",
       "      <td>&lt;0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ax1, median [Q1,Q3]</th>\n",
       "      <th></th>\n",
       "      <td>0</td>\n",
       "      <td>0.22 [0.04,0.43]</td>\n",
       "      <td>0.22 [0.04,0.43]</td>\n",
       "      <td>0.09 [-0.08,0.28]</td>\n",
       "      <td>&lt;0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ax2, median [Q1,Q3]</th>\n",
       "      <th></th>\n",
       "      <td>0</td>\n",
       "      <td>0.19 [0.04,0.40]</td>\n",
       "      <td>0.19 [0.05,0.40]</td>\n",
       "      <td>0.04 [-0.12,0.18]</td>\n",
       "      <td>&lt;0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"20\" valign=\"top\">Sector, n (%)</th>\n",
       "      <th>Actividades art√≠sticas, de entretenimiento y recreaci√≥n</th>\n",
       "      <td>0</td>\n",
       "      <td>88 (0.52)</td>\n",
       "      <td>86 (0.52)</td>\n",
       "      <td>2 (0.63)</td>\n",
       "      <td>&lt;0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actividades de atenci√≥n de la salud humana y de asistencia social</th>\n",
       "      <td></td>\n",
       "      <td>64 (0.38)</td>\n",
       "      <td>63 (0.38)</td>\n",
       "      <td>1 (0.31)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actividades de organizaciones y entidades extraterritoriales</th>\n",
       "      <td></td>\n",
       "      <td>3 (0.02)</td>\n",
       "      <td>3 (0.02)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actividades de servicios administrativos y de apoyo</th>\n",
       "      <td></td>\n",
       "      <td>646 (3.84)</td>\n",
       "      <td>632 (3.83)</td>\n",
       "      <td>14 (4.40)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actividades financieras y de seguros</th>\n",
       "      <td></td>\n",
       "      <td>474 (2.82)</td>\n",
       "      <td>473 (2.87)</td>\n",
       "      <td>1 (0.31)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actividades inmobiliarias</th>\n",
       "      <td></td>\n",
       "      <td>1449 (8.62)</td>\n",
       "      <td>1443 (8.75)</td>\n",
       "      <td>6 (1.89)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actividades profesionales,  cient√≠ficas y t√©cnicas</th>\n",
       "      <td></td>\n",
       "      <td>1142 (6.80)</td>\n",
       "      <td>1127 (6.84)</td>\n",
       "      <td>15 (4.72)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Administraci√≥n p√∫blica y defensa; planes de seguridad social de afiliaci√≥n obligatoria</th>\n",
       "      <td></td>\n",
       "      <td>4 (0.02)</td>\n",
       "      <td>4 (0.02)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Agricultura, ganader√≠a, caza, silvicultura y pesca</th>\n",
       "      <td></td>\n",
       "      <td>1012 (6.02)</td>\n",
       "      <td>990 (6.00)</td>\n",
       "      <td>22 (6.92)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alojamiento y servicios de comida</th>\n",
       "      <td></td>\n",
       "      <td>363 (2.16)</td>\n",
       "      <td>349 (2.12)</td>\n",
       "      <td>14 (4.40)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Comercio al por mayor y al por menor; reparaci√≥n de veh√≠culos automotores y motocicletas</th>\n",
       "      <td></td>\n",
       "      <td>5288 (31.46)</td>\n",
       "      <td>5201 (31.54)</td>\n",
       "      <td>87 (27.36)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Construcci√≥n</th>\n",
       "      <td></td>\n",
       "      <td>2238 (13.32)</td>\n",
       "      <td>2190 (13.28)</td>\n",
       "      <td>48 (15.09)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Distribuci√≥n de agua; evacuaci√≥n y tratamiento de aguas residuales, gesti√≥n de desechos y actividades de saneanmiento ambiental</th>\n",
       "      <td></td>\n",
       "      <td>28 (0.17)</td>\n",
       "      <td>27 (0.16)</td>\n",
       "      <td>1 (0.31)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Educaci√≥n</th>\n",
       "      <td></td>\n",
       "      <td>87 (0.52)</td>\n",
       "      <td>86 (0.52)</td>\n",
       "      <td>1 (0.31)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Explotaci√≥n de minas y canteras</th>\n",
       "      <td></td>\n",
       "      <td>282 (1.68)</td>\n",
       "      <td>277 (1.68)</td>\n",
       "      <td>5 (1.57)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Industrias manufacturetas</th>\n",
       "      <td></td>\n",
       "      <td>2735 (16.27)</td>\n",
       "      <td>2647 (16.05)</td>\n",
       "      <td>88 (27.67)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Informaci√≥n y comunicaciones</th>\n",
       "      <td></td>\n",
       "      <td>464 (2.76)</td>\n",
       "      <td>456 (2.77)</td>\n",
       "      <td>8 (2.52)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Otras actividades de servicios</th>\n",
       "      <td></td>\n",
       "      <td>115 (0.68)</td>\n",
       "      <td>114 (0.69)</td>\n",
       "      <td>1 (0.31)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Suministro de electricidad, gas, vapor y aire acondicionado</th>\n",
       "      <td></td>\n",
       "      <td>10 (0.06)</td>\n",
       "      <td>10 (0.06)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Transporte y almacenamiento</th>\n",
       "      <td></td>\n",
       "      <td>314 (1.87)</td>\n",
       "      <td>310 (1.88)</td>\n",
       "      <td>4 (1.26)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><br />[1] Chi-squared tests for the following variables may be invalid due to the low number of observations: time-event, Sector.<br />"
      ],
      "text/plain": [
       "                                                                                                                                                    Grouped by event                                                                \n",
       "                                                                                                                                                             Missing           Overall               0.0                 1.0 P-Value\n",
       "n                                                                                                                                                                                16806             16488                 318        \n",
       "time-event, n (%)   0.0                                                                                                                                            0     16488 (98.11)    16488 (100.00)                      <0.001\n",
       "                    2017.0                                                                                                                                                   99 (0.59)                            99 (31.13)        \n",
       "                    2018.0                                                                                                                                                   96 (0.57)                            96 (30.19)        \n",
       "                    2019.0                                                                                                                                                  123 (0.73)                           123 (38.68)        \n",
       "MGB, median [Q1,Q3]                                                                                                                                                0  0.31 [0.18,0.56]  0.32 [0.18,0.56]    0.26 [0.14,0.41]  <0.001\n",
       "MGN, median [Q1,Q3]                                                                                                                                                0  0.03 [0.00,0.08]  0.03 [0.00,0.08]  -0.02 [-0.18,0.03]  <0.001\n",
       "ROE, median [Q1,Q3]                                                                                                                                                0  0.07 [0.01,0.16]  0.07 [0.01,0.16]   0.01 [-0.18,0.09]  <0.001\n",
       "ROA, median [Q1,Q3]                                                                                                                                                0  0.03 [0.00,0.06]  0.03 [0.00,0.07]  -0.01 [-0.09,0.01]  <0.001\n",
       "NE, median [Q1,Q3]                                                                                                                                                 0  0.53 [0.32,0.72]  0.52 [0.32,0.72]    0.74 [0.59,0.88]  <0.001\n",
       "PCP, median [Q1,Q3]                                                                                                                                                0  0.75 [0.45,0.98]  0.75 [0.45,0.98]    0.53 [0.28,0.87]  <0.001\n",
       "Ax1, median [Q1,Q3]                                                                                                                                                0  0.22 [0.04,0.43]  0.22 [0.04,0.43]   0.09 [-0.08,0.28]  <0.001\n",
       "Ax2, median [Q1,Q3]                                                                                                                                                0  0.19 [0.04,0.40]  0.19 [0.05,0.40]   0.04 [-0.12,0.18]  <0.001\n",
       "Sector, n (%)       Actividades art√≠sticas, de entretenimiento y recreaci√≥n                                                                                        0         88 (0.52)         86 (0.52)            2 (0.63)  <0.001\n",
       "                    Actividades de atenci√≥n de la salud humana y de asistencia social                                                                                        64 (0.38)         63 (0.38)            1 (0.31)        \n",
       "                    Actividades de organizaciones y entidades extraterritoriales                                                                                              3 (0.02)          3 (0.02)                            \n",
       "                    Actividades de servicios administrativos y de apoyo                                                                                                     646 (3.84)        632 (3.83)           14 (4.40)        \n",
       "                    Actividades financieras y de seguros                                                                                                                    474 (2.82)        473 (2.87)            1 (0.31)        \n",
       "                    Actividades inmobiliarias                                                                                                                              1449 (8.62)       1443 (8.75)            6 (1.89)        \n",
       "                    Actividades profesionales,  cient√≠ficas y t√©cnicas                                                                                                     1142 (6.80)       1127 (6.84)           15 (4.72)        \n",
       "                    Administraci√≥n p√∫blica y defensa; planes de seguridad social de afiliaci√≥n obligatoria                                                                    4 (0.02)          4 (0.02)                            \n",
       "                    Agricultura, ganader√≠a, caza, silvicultura y pesca                                                                                                     1012 (6.02)        990 (6.00)           22 (6.92)        \n",
       "                    Alojamiento y servicios de comida                                                                                                                       363 (2.16)        349 (2.12)           14 (4.40)        \n",
       "                    Comercio al por mayor y al por menor; reparaci√≥n de veh√≠culos automotores y motocicletas                                                              5288 (31.46)      5201 (31.54)          87 (27.36)        \n",
       "                    Construcci√≥n                                                                                                                                          2238 (13.32)      2190 (13.28)          48 (15.09)        \n",
       "                    Distribuci√≥n de agua; evacuaci√≥n y tratamiento de aguas residuales, gesti√≥n de desechos y actividades de saneanmiento ambiental                          28 (0.17)         27 (0.16)            1 (0.31)        \n",
       "                    Educaci√≥n                                                                                                                                                87 (0.52)         86 (0.52)            1 (0.31)        \n",
       "                    Explotaci√≥n de minas y canteras                                                                                                                         282 (1.68)        277 (1.68)            5 (1.57)        \n",
       "                    Industrias manufacturetas                                                                                                                             2735 (16.27)      2647 (16.05)          88 (27.67)        \n",
       "                    Informaci√≥n y comunicaciones                                                                                                                            464 (2.76)        456 (2.77)            8 (2.52)        \n",
       "                    Otras actividades de servicios                                                                                                                          115 (0.68)        114 (0.69)            1 (0.31)        \n",
       "                    Suministro de electricidad, gas, vapor y aire acondicionado                                                                                              10 (0.06)         10 (0.06)                            \n",
       "                    Transporte y almacenamiento                                                                                                                             314 (1.87)        310 (1.88)            4 (1.26)        \n",
       "[1] Chi-squared tests for the following variables may be invalid due to the low number of observations: time-event, Sector."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\n#####################\\n#Correlation graph###\\n####################\\n\\n\\ncorrMatrix = df_train.iloc[:, 2:-1].corr(method=\\'spearman\\')\\nCorrMatrix = corrMatrix.where(np.tril(np.ones(corrMatrix.shape)).astype(\\'bool\\'))\\nwith sns.axes_style(\"white\"):\\n    f, ax = plt.subplots(figsize=(12, 8))\\n    ax = sns.heatmap(CorrMatrix, annot=True, cmap=\"gray_r\")\\nplt.savefig(\\'Matrix.eps\\')\\n\\n\\n\\n\\n###################\\n## Modelling Xy  ##\\n###################\\ndf_train = df_train[[ \\'event\\'] + predictors]\\ndf = df_train.copy() \\ndf.reset_index(drop=True, inplace=True) # It is necessary for the next function\\ncat, nonormal, normal  = breakdown_vars(df)\\ndf = dummies_ohe(df_train,cat)\\nX,y = Xy(df,\\'event\\')\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, shuffle = True, random_state = 666, stratify=y)\\n\\n\\nprint(y_train.value_counts())\\nprint(y_test.value_counts())\\n\\n\\n\\n### Logit model\\nbest_model = grid_lr(X_train, y_train)\\npreds = best_model.predict(X_test)\\nprint(classification_report(y_test, preds))  # recall igual a sensibilidad\\nlogit  = pd.DataFrame(classification_report(y_test, preds , output_dict=True)).iloc[:,0:2]\\n\\n\\n\\n\\n\\n### Decision tree\\nbest_model = grid_dt(X_train, y_train)\\npreds = best_model.predict(X_test)\\nprint(classification_report(y_test, preds))  # recall igual a sensibilidad\\ntree = pd.DataFrame(classification_report(y_test, preds , output_dict=True)).iloc[:,0:2]\\n\\n\\n\\n### Modelling perceptron\\nbest_model = grid_MLP(X_train, y_train)\\npreds = best_model.predict(X_test)\\nprint(classification_report(y_test, preds))  # recall igual a sensibilidad\\nMLP =  pd.DataFrame(classification_report(y_test, preds , output_dict=True)).iloc[:,0:2]\\n\\n\\n\\nmodels_tab = pd.concat([logit, tree, MLP], axis=1)\\ncols_names =  pd.MultiIndex.from_tuples([(\\'Logistic Regression\\',\\'No-Default\\'),(\"Logistic Regression\",\\'Deafult\\'),\\n              (\"Decision Tree  \",\\'No-Default\\'),(\\'Decision Tree  \\',\\'Default\\'),\\n              (\"Multilayer Perceptron\",\\'No-Default\\'),(\\'Multilayer Perceptron\\',\\'Default\\')])\\nmodels_tab.columns  = cols_names\\nmodels_tab = models_tab.style.set_table_styles([\\n   {\\'selector\\': \\'th\\',\\'props\\': [(\\'text-align\\', \\'center\\')]}]).format(precision=2)\\nmodels_tab.to_latex(\"lag1results.tex\")\\n\\ndisplay(models_tab)\\n\\n\\n##################################\\n# Modelling with undersampling   #\\n##################################\\n\\n\\nfrom imblearn.under_sampling import RandomUnderSampler\\nrus = RandomUnderSampler(random_state=1234)\\nX_res, y_res = rus.fit_resample(X, y)\\nX_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.30, shuffle = True, random_state = 666, stratify=y_res)\\n\\nprint(y_train.value_counts())\\nprint(y_test.value_counts())\\n\\n\\n##### Results undersampling\\n\\n\\n### Logit model\\nbest_model = grid_lr(X_train, y_train)\\npreds = best_model.predict(X_test)\\nprint(classification_report(y_test, preds))  # recall igual a sensibilidad\\nlogit  = pd.DataFrame(classification_report(y_test, preds , output_dict=True)).iloc[:,0:2]\\n\\n\\n### Decision tree\\nbest_model = grid_dt(X_train, y_train)\\npreds = best_model.predict(X_test)\\nprint(classification_report(y_test, preds))  # recall igual a sensibilidad\\ntree = pd.DataFrame(classification_report(y_test, preds , output_dict=True)).iloc[:,0:2]\\n\\n\\n### Modelling perceptron\\nbest_model = grid_MLP(X_train, y_train)\\npreds = best_model.predict(X_test)\\nprint(classification_report(y_test, preds))  # recall igual a sensibilidad\\nMLP =  pd.DataFrame(classification_report(y_test, preds , output_dict=True)).iloc[:,0:2]\\n\\n\\n\\n\\n\\nmodels_tab = pd.concat([logit, tree, MLP], axis=1)\\ncols_names =  pd.MultiIndex.from_tuples([(\\'Logistic Regression\\',\\'No-Default\\'),(\"Logistic Regression\",\\'Deafult\\'),\\n              (\"Decision Tree  \",\\'No-Default\\'),(\\'Decision Tree  \\',\\'Default\\'),\\n              (\"Multilayer Perceptron\",\\'No-Default\\'),(\\'Multilayer Perceptron\\',\\'Default\\')])\\nmodels_tab.columns  = cols_names\\nmodels_tab = models_tab.style.set_table_styles([\\n   {\\'selector\\': \\'th\\',\\'props\\': [(\\'text-align\\', \\'center\\')]}]).format(precision=2)\\nmodels_tab.to_latex(\"underlag1results.tex\")\\nmodels_tab\\n'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######################\n",
    "# POOLED MODEL lag=1##\n",
    "#####################\n",
    "df_train = pd.read_csv(\"Datapooled.csv\")\n",
    "df_train = df_train[VARS+['NIT', 'event', 'time-event', 'Sector']]\n",
    "print(df['event'].value_counts())\n",
    "print(df_train[df_train['event']==1].info())\n",
    "df_train['complete-vars'] = complete_vars(df_train) #1 is that have all variables!\n",
    "df_train =  df_train[df_train['complete-vars']==1] #filtering firms that have not financial information \n",
    "print(df_train[df_train['event']==1].info())\n",
    "df_train = ratios(df_train)\n",
    "predictors =[ 'MGB', 'MGN', 'ROE','ROA', 'NE', 'PCP',  'Ax1', 'Ax2', 'Sector']\n",
    "\n",
    "print(df_train[df_train['event']==1].info())\n",
    "df_train.replace([np.inf,-np.inf], np.nan, inplace=True)\n",
    "df_train.dropna(inplace=True)\n",
    "\n",
    "#*\n",
    "df_tab = df_train = df_train[[ 'event' , 'time-event'] + predictors].copy()\n",
    "df_tab['time-event'] = df_tab['time-event'].astype('str')\n",
    "#*\n",
    "\n",
    "\n",
    "###################\n",
    "#   TABLE ONE     #\n",
    "###################\n",
    "df_tab.reset_index(drop=True, inplace=True) # It is necessary for the next function\n",
    "cat, nonormal, normal  = breakdown_vars(df_tab)\n",
    "df = std_z(nonormal + normal, df, 'event')  # Standardize the variables (WORK) study this properties\n",
    "mytable = TableOne(df_tab, categorical=cat, nonnormal=nonormal,  groupby='event', pval=True, decimals=2)\n",
    "display(mytable)\n",
    "mytable.to_latex(\"tableonelag1.tex\")\n",
    "mytable.to_excel(\"tableonelag1.xlsx\")\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#####################\n",
    "#Correlation graph###\n",
    "####################\n",
    "\n",
    "\n",
    "corrMatrix = df_train.iloc[:, 2:-1].corr(method='spearman')\n",
    "CorrMatrix = corrMatrix.where(np.tril(np.ones(corrMatrix.shape)).astype('bool'))\n",
    "with sns.axes_style(\"white\"):\n",
    "    f, ax = plt.subplots(figsize=(12, 8))\n",
    "    ax = sns.heatmap(CorrMatrix, annot=True, cmap=\"gray_r\")\n",
    "plt.savefig('Matrix.eps')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###################\n",
    "## Modelling Xy  ##\n",
    "###################\n",
    "df_train = df_train[[ 'event'] + predictors]\n",
    "df = df_train.copy() \n",
    "df.reset_index(drop=True, inplace=True) # It is necessary for the next function\n",
    "cat, nonormal, normal  = breakdown_vars(df)\n",
    "df = dummies_ohe(df_train,cat)\n",
    "X,y = Xy(df,'event')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, shuffle = True, random_state = 666, stratify=y)\n",
    "\n",
    "\n",
    "print(y_train.value_counts())\n",
    "print(y_test.value_counts())\n",
    "\n",
    "\n",
    "\n",
    "### Logit model\n",
    "best_model = grid_lr(X_train, y_train)\n",
    "preds = best_model.predict(X_test)\n",
    "print(classification_report(y_test, preds))  # recall igual a sensibilidad\n",
    "logit  = pd.DataFrame(classification_report(y_test, preds , output_dict=True)).iloc[:,0:2]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Decision tree\n",
    "best_model = grid_dt(X_train, y_train)\n",
    "preds = best_model.predict(X_test)\n",
    "print(classification_report(y_test, preds))  # recall igual a sensibilidad\n",
    "tree = pd.DataFrame(classification_report(y_test, preds , output_dict=True)).iloc[:,0:2]\n",
    "\n",
    "\n",
    "\n",
    "### Modelling perceptron\n",
    "best_model = grid_MLP(X_train, y_train)\n",
    "preds = best_model.predict(X_test)\n",
    "print(classification_report(y_test, preds))  # recall igual a sensibilidad\n",
    "MLP =  pd.DataFrame(classification_report(y_test, preds , output_dict=True)).iloc[:,0:2]\n",
    "\n",
    "\n",
    "\n",
    "models_tab = pd.concat([logit, tree, MLP], axis=1)\n",
    "cols_names =  pd.MultiIndex.from_tuples([('Logistic Regression','No-Default'),(\"Logistic Regression\",'Deafult'),\n",
    "              (\"Decision Tree  \",'No-Default'),('Decision Tree  ','Default'),\n",
    "              (\"Multilayer Perceptron\",'No-Default'),('Multilayer Perceptron','Default')])\n",
    "models_tab.columns  = cols_names\n",
    "models_tab = models_tab.style.set_table_styles([\n",
    "   {'selector': 'th','props': [('text-align', 'center')]}]).format(precision=2)\n",
    "models_tab.to_latex(\"lag1results.tex\")\n",
    "\n",
    "display(models_tab)\n",
    "\n",
    "\n",
    "##################################\n",
    "# Modelling with undersampling   #\n",
    "##################################\n",
    "\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=1234)\n",
    "X_res, y_res = rus.fit_resample(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.30, shuffle = True, random_state = 666, stratify=y_res)\n",
    "\n",
    "print(y_train.value_counts())\n",
    "print(y_test.value_counts())\n",
    "\n",
    "\n",
    "##### Results undersampling\n",
    "\n",
    "\n",
    "### Logit model\n",
    "best_model = grid_lr(X_train, y_train)\n",
    "preds = best_model.predict(X_test)\n",
    "print(classification_report(y_test, preds))  # recall igual a sensibilidad\n",
    "logit  = pd.DataFrame(classification_report(y_test, preds , output_dict=True)).iloc[:,0:2]\n",
    "\n",
    "\n",
    "### Decision tree\n",
    "best_model = grid_dt(X_train, y_train)\n",
    "preds = best_model.predict(X_test)\n",
    "print(classification_report(y_test, preds))  # recall igual a sensibilidad\n",
    "tree = pd.DataFrame(classification_report(y_test, preds , output_dict=True)).iloc[:,0:2]\n",
    "\n",
    "\n",
    "### Modelling perceptron\n",
    "best_model = grid_MLP(X_train, y_train)\n",
    "preds = best_model.predict(X_test)\n",
    "print(classification_report(y_test, preds))  # recall igual a sensibilidad\n",
    "MLP =  pd.DataFrame(classification_report(y_test, preds , output_dict=True)).iloc[:,0:2]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "models_tab = pd.concat([logit, tree, MLP], axis=1)\n",
    "cols_names =  pd.MultiIndex.from_tuples([('Logistic Regression','No-Default'),(\"Logistic Regression\",'Deafult'),\n",
    "              (\"Decision Tree  \",'No-Default'),('Decision Tree  ','Default'),\n",
    "              (\"Multilayer Perceptron\",'No-Default'),('Multilayer Perceptron','Default')])\n",
    "models_tab.columns  = cols_names\n",
    "models_tab = models_tab.style.set_table_styles([\n",
    "   {'selector': 'th','props': [('text-align', 'center')]}]).format(precision=2)\n",
    "models_tab.to_latex(\"underlag1results.tex\")\n",
    "models_tab\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f4a51b65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "event\n",
       "0.0    16488\n",
       "1.0      318\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['event'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "533b1b6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16806, 23)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50553765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\ndf_train = pd.read_csv(\"Datapooled2.csv\")\\ndf_train = df_train[VARS+[\\'NIT\\', \\'event\\', \\'time-event\\',  \\'Sector\\']]\\nprint(df_train[df_train[\\'event\\']==1].info())\\ndf_train[\\'complete-vars\\'] = complete_vars(df_train) #1 is that have all variables!\\ndf_train =  df_train[df_train[\\'complete-vars\\']==1] #filtering firms that have not financial information \\nprint(df_train[df_train[\\'event\\']==1].info())\\ndf_train = ratios(df_train)\\npredictors =[ \\'MGB\\', \\'MGN\\', \\'ROE\\',\\'ROA\\', \\'NE\\', \\'PCP\\',  \\'Ax1\\', \\'Ax2\\',\\n             \\'Sector\\']\\n\\nprint(df_train[df_train[\\'event\\']==1].info())\\ndf_train.replace([np.inf,-np.inf], np.nan, inplace=True)\\ndf_train.dropna(inplace=True)\\n\\n#*\\ndf_tab = df_train = df_train[[ \\'event\\' , \\'time-event\\'] + predictors].copy()\\ndf_tab[\\'time-event\\'] = df_tab[\\'time-event\\'].astype(\\'str\\')\\n#*\\n\\n\\n###################\\n#   TABLE ONE     #\\n###################\\ndf_tab.reset_index(drop=True, inplace=True) # It is necessary for the next function\\ncat, nonormal, normal  = breakdown_vars(df_tab)\\n#df = std_z(nonormal + normal, df, \\'event\\')  # Standardize the variables (WORK) study this properties\\nmytable = TableOne(df_tab, categorical=cat, nonnormal=nonormal,  groupby=\\'event\\', pval=True, decimals=2)\\ndisplay(mytable)\\nmytable.to_latex(\"tableonelag2.tex\")\\n\\n\\n\\n###################\\n## Modelling Xy  ##\\n###################\\ndf_train = df_train[[ \\'event\\'] + predictors]\\ndf = df_train.copy() \\ndf.reset_index(drop=True, inplace=True) # It is necessary for the next function\\ncat, nonormal, normal  = breakdown_vars(df)\\ndf = dummies_ohe(df_train,cat)\\nX,y = Xy(df,\\'event\\')\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle = True, random_state = 666, stratify=y)\\n\\n\\nprint(y_train.value_counts())\\nprint(y_test.value_counts())\\n\\n\\n\\n\\n\\n\\n### Logit model\\nbest_model = grid_lr(X_train, y_train)\\npreds = best_model.predict(X_test)\\nprint(classification_report(y_test, preds))  # recall igual a sensibilidad\\nlogit  = pd.DataFrame(classification_report(y_test, preds , output_dict=True)).iloc[:,0:2]\\n\\n\\n\\n### Decision tree\\nbest_model = grid_dt(X_train, y_train)\\npreds = best_model.predict(X_test)\\nprint(classification_report(y_test, preds))  # recall igual a sensibilidad\\ntree = pd.DataFrame(classification_report(y_test, preds , output_dict=True)).iloc[:,0:2]\\n\\n\\n\\n### Modelling perceptron\\nbest_model = grid_MLP(X_train, y_train)\\npreds = best_model.predict(X_test)\\nprint(classification_report(y_test, preds))  # recall igual a sensibilidad\\nMLP =  pd.DataFrame(classification_report(y_test, preds , output_dict=True)).iloc[:,0:2]\\n\\n\\n\\n\\n\\nmodels_tab = pd.concat([logit, tree, MLP], axis=1)\\ncols_names =  pd.MultiIndex.from_tuples([(\\'Logistic Regression\\',\\'No-Default\\'),(\"Logistic Regression\",\\'Deafult\\'),\\n              (\"Decision Tree  \",\\'No-Default\\'),(\\'Decision Tree  \\',\\'Default\\'),\\n              (\"Multilayer Perceptron\",\\'No-Default\\'),(\\'Multilayer Perceptron\\',\\'Default\\')])\\nmodels_tab.columns  = cols_names\\nmodels_tab = models_tab.style.set_table_styles([\\n   {\\'selector\\': \\'th\\',\\'props\\': [(\\'text-align\\', \\'center\\')]}]).format(precision=2)\\nmodels_tab.to_latex(\"lag2results.tex\")\\n\\ndisplay(models_tab)\\n\\n##################################\\n# Modelling with undersampling   #\\n##################################\\n\\nfrom imblearn.under_sampling import RandomUnderSampler\\nrus = RandomUnderSampler(random_state=1234)\\nX_res, y_res = rus.fit_resample(X, y)\\nX_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, shuffle = True, random_state = 666, stratify=y_res)\\n\\n\\n\\n##### Results undersampling\\n\\n\\n\\n### Logit model\\nbest_model = grid_lr(X_train, y_train)\\npreds = best_model.predict(X_test)\\nprint(classification_report(y_test, preds))  # recall igual a sensibilidad\\nlogit  = pd.DataFrame(classification_report(y_test, preds , output_dict=True)).iloc[:,0:2]\\n\\n\\n### Decision tree\\nbest_model = grid_dt(X_train, y_train)\\npreds = best_model.predict(X_test)\\nprint(classification_report(y_test, preds))  # recall igual a sensibilidad\\ntree = pd.DataFrame(classification_report(y_test, preds , output_dict=True)).iloc[:,0:2]\\n\\n\\n### Modelling perceptron\\nbest_model = grid_MLP(X_train, y_train)\\npreds = best_model.predict(X_test)\\nprint(classification_report(y_test, preds))  # recall igual a sensibilidad\\nMLP =  pd.DataFrame(classification_report(y_test, preds , output_dict=True)).iloc[:,0:2]\\n\\n\\nmodels_tab = pd.concat([logit, tree, MLP], axis=1)\\ncols_names =  pd.MultiIndex.from_tuples([(\\'Logistic Regression\\',\\'No-Default\\'),(\"Logistic Regression\",\\'Deafult\\'),\\n              (\"Decision Tree  \",\\'No-Default\\'),(\\'Decision Tree  \\',\\'Default\\'),\\n              (\"Multilayer Perceptron\",\\'No-Default\\'),(\\'Multilayer Perceptron\\',\\'Default\\')])\\nmodels_tab.columns  = cols_names\\nmodels_tab = models_tab.style.set_table_styles([\\n   {\\'selector\\': \\'th\\',\\'props\\': [(\\'text-align\\', \\'center\\')]}]).format(precision=2)\\nmodels_tab.to_latex(\"underlag2results.tex\")\\nmodels_tab\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##########################\n",
    "# Estimation with lag=2  #\n",
    "##########################\n",
    "\"\"\"\n",
    "\n",
    "df_train = pd.read_csv(\"Datapooled2.csv\")\n",
    "df_train = df_train[VARS+['NIT', 'event', 'time-event',  'Sector']]\n",
    "print(df_train[df_train['event']==1].info())\n",
    "df_train['complete-vars'] = complete_vars(df_train) #1 is that have all variables!\n",
    "df_train =  df_train[df_train['complete-vars']==1] #filtering firms that have not financial information \n",
    "print(df_train[df_train['event']==1].info())\n",
    "df_train = ratios(df_train)\n",
    "predictors =[ 'MGB', 'MGN', 'ROE','ROA', 'NE', 'PCP',  'Ax1', 'Ax2',\n",
    "             'Sector']\n",
    "\n",
    "print(df_train[df_train['event']==1].info())\n",
    "df_train.replace([np.inf,-np.inf], np.nan, inplace=True)\n",
    "df_train.dropna(inplace=True)\n",
    "\n",
    "#*\n",
    "df_tab = df_train = df_train[[ 'event' , 'time-event'] + predictors].copy()\n",
    "df_tab['time-event'] = df_tab['time-event'].astype('str')\n",
    "#*\n",
    "\n",
    "\n",
    "###################\n",
    "#   TABLE ONE     #\n",
    "###################\n",
    "df_tab.reset_index(drop=True, inplace=True) # It is necessary for the next function\n",
    "cat, nonormal, normal  = breakdown_vars(df_tab)\n",
    "#df = std_z(nonormal + normal, df, 'event')  # Standardize the variables (WORK) study this properties\n",
    "mytable = TableOne(df_tab, categorical=cat, nonnormal=nonormal,  groupby='event', pval=True, decimals=2)\n",
    "display(mytable)\n",
    "mytable.to_latex(\"tableonelag2.tex\")\n",
    "\n",
    "\n",
    "\n",
    "###################\n",
    "## Modelling Xy  ##\n",
    "###################\n",
    "df_train = df_train[[ 'event'] + predictors]\n",
    "df = df_train.copy() \n",
    "df.reset_index(drop=True, inplace=True) # It is necessary for the next function\n",
    "cat, nonormal, normal  = breakdown_vars(df)\n",
    "df = dummies_ohe(df_train,cat)\n",
    "X,y = Xy(df,'event')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle = True, random_state = 666, stratify=y)\n",
    "\n",
    "\n",
    "print(y_train.value_counts())\n",
    "print(y_test.value_counts())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Logit model\n",
    "best_model = grid_lr(X_train, y_train)\n",
    "preds = best_model.predict(X_test)\n",
    "print(classification_report(y_test, preds))  # recall igual a sensibilidad\n",
    "logit  = pd.DataFrame(classification_report(y_test, preds , output_dict=True)).iloc[:,0:2]\n",
    "\n",
    "\n",
    "\n",
    "### Decision tree\n",
    "best_model = grid_dt(X_train, y_train)\n",
    "preds = best_model.predict(X_test)\n",
    "print(classification_report(y_test, preds))  # recall igual a sensibilidad\n",
    "tree = pd.DataFrame(classification_report(y_test, preds , output_dict=True)).iloc[:,0:2]\n",
    "\n",
    "\n",
    "\n",
    "### Modelling perceptron\n",
    "best_model = grid_MLP(X_train, y_train)\n",
    "preds = best_model.predict(X_test)\n",
    "print(classification_report(y_test, preds))  # recall igual a sensibilidad\n",
    "MLP =  pd.DataFrame(classification_report(y_test, preds , output_dict=True)).iloc[:,0:2]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "models_tab = pd.concat([logit, tree, MLP], axis=1)\n",
    "cols_names =  pd.MultiIndex.from_tuples([('Logistic Regression','No-Default'),(\"Logistic Regression\",'Deafult'),\n",
    "              (\"Decision Tree  \",'No-Default'),('Decision Tree  ','Default'),\n",
    "              (\"Multilayer Perceptron\",'No-Default'),('Multilayer Perceptron','Default')])\n",
    "models_tab.columns  = cols_names\n",
    "models_tab = models_tab.style.set_table_styles([\n",
    "   {'selector': 'th','props': [('text-align', 'center')]}]).format(precision=2)\n",
    "models_tab.to_latex(\"lag2results.tex\")\n",
    "\n",
    "display(models_tab)\n",
    "\n",
    "##################################\n",
    "# Modelling with undersampling   #\n",
    "##################################\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=1234)\n",
    "X_res, y_res = rus.fit_resample(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, shuffle = True, random_state = 666, stratify=y_res)\n",
    "\n",
    "\n",
    "\n",
    "##### Results undersampling\n",
    "\n",
    "\n",
    "\n",
    "### Logit model\n",
    "best_model = grid_lr(X_train, y_train)\n",
    "preds = best_model.predict(X_test)\n",
    "print(classification_report(y_test, preds))  # recall igual a sensibilidad\n",
    "logit  = pd.DataFrame(classification_report(y_test, preds , output_dict=True)).iloc[:,0:2]\n",
    "\n",
    "\n",
    "### Decision tree\n",
    "best_model = grid_dt(X_train, y_train)\n",
    "preds = best_model.predict(X_test)\n",
    "print(classification_report(y_test, preds))  # recall igual a sensibilidad\n",
    "tree = pd.DataFrame(classification_report(y_test, preds , output_dict=True)).iloc[:,0:2]\n",
    "\n",
    "\n",
    "### Modelling perceptron\n",
    "best_model = grid_MLP(X_train, y_train)\n",
    "preds = best_model.predict(X_test)\n",
    "print(classification_report(y_test, preds))  # recall igual a sensibilidad\n",
    "MLP =  pd.DataFrame(classification_report(y_test, preds , output_dict=True)).iloc[:,0:2]\n",
    "\n",
    "\n",
    "models_tab = pd.concat([logit, tree, MLP], axis=1)\n",
    "cols_names =  pd.MultiIndex.from_tuples([('Logistic Regression','No-Default'),(\"Logistic Regression\",'Deafult'),\n",
    "              (\"Decision Tree  \",'No-Default'),('Decision Tree  ','Default'),\n",
    "              (\"Multilayer Perceptron\",'No-Default'),('Multilayer Perceptron','Default')])\n",
    "models_tab.columns  = cols_names\n",
    "models_tab = models_tab.style.set_table_styles([\n",
    "   {'selector': 'th','props': [('text-align', 'center')]}]).format(precision=2)\n",
    "models_tab.to_latex(\"underlag2results.tex\")\n",
    "models_tab\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d30e954a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.756757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.589474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.732394</td>\n",
       "      <td>0.662722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>96.000000</td>\n",
       "      <td>95.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0.0        1.0\n",
       "precision   0.666667   0.756757\n",
       "recall      0.812500   0.589474\n",
       "f1-score    0.732394   0.662722\n",
       "support    96.000000  95.000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4cc674bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.614865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.406250</td>\n",
       "      <td>0.957895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.561151</td>\n",
       "      <td>0.748971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>96.000000</td>\n",
       "      <td>95.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0.0        1.0\n",
       "precision   0.906977   0.614865\n",
       "recall      0.406250   0.957895\n",
       "f1-score    0.561151   0.748971\n",
       "support    96.000000  95.000000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07dd3177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.639640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.747368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.689320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>96.000000</td>\n",
       "      <td>95.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0.0        1.0\n",
       "precision   0.700000   0.639640\n",
       "recall      0.583333   0.747368\n",
       "f1-score    0.636364   0.689320\n",
       "support    96.000000  95.000000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
